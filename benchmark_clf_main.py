import argparse
import sys

import pandas as pd
import xgboost as xgb
from clfs import benchmark_classification
import utils
from data import main_u

def parse_args(args):
    parser = argparse.ArgumentParser()

    # synthetic dataset path
    parser.add_argument('--features', default="/home/silver/PycharmProjects/AAEDRL/AAE/ds_fin2.csv")
    # generated labels path
    parser.add_argument('--labels', default="/home/silver/PycharmProjects/AAEDRL/clfs/labels.csv")

    parser.add_argument("--unaug_dataset", action = "store_true")

    # CLASSIFIERS: !!! TO USE GB, keep the following arguments in False (a printed message will appear to confirm the classifier used) !!!
    parser.add_argument("--xgb_clf", default= False, type=bool)
    parser.add_argument("--KNN_clf", default= False, type=bool)
    parser.add_argument("--rf_clf", default= False, type=bool)

    return parser.parse_args(args)

if __name__ == "__main__":
    args = sys.argv[1:]
    args = parse_args(args)
    # AUGMENTED DATASET : if unaugmented we used another dataset (generated by the decoder)
    df = pd.DataFrame(pd.read_csv(args.features))
    # Split the dataset types to undo the scaling performed on continuous features 
    df_disc, df_cont = main_u.df_type_split(df) # discrete and continuous features
    _, mainX_cont = main_u.df_type_split(main_u.X) # The scaled continuous features (ignore discrete)
    X_inv = utils.inverse_sc_cont(mainX_cont, df_cont) # Undo the scaling : ground truth is the continuous features before scaling
    X = df_disc.join(X_inv) # Join the unscaled features with discrete features
    
    # LABELS FOR AUGMENTED DATASET: it was generated for the synthetic data generated by our UNAUGMENTED DECODER and the original labels (main_u.y)
    # To use the unaugmented dataset we need the labels in main_u.y 
    # To clarify: 
    # 1/ we trained the AAE on unaugmented dataset -> Performed benchmark classification using the dataset generated by the decoder and the original labels (main_u.y)
    # 2/ we generate labels using TabNet for the data generated by the decoder -> we trained the DRL algorithm and generate new synthetic dataset
    # 3/ we generate labels again for the new synthetic dataset -> augmented dataset = new synthetic dataset generated using DRL + original dataset
    # 4/ we trained the AAE on augmented dataset where we use the labels generated in STEP 3 -> performed benchmark classification using the dataset generated by the augmented decoder and the labels generated in STEP 2 plus original labels
    # => Establish ground truth
    if args.unaug_dataset:
        print("using original y")
        y = main_u.y
        X_train, X_test, y_train, y_test = main_u.vertical_split(X, y)
        benchmark_classification.clf_class(X_train, X_test, y_train, y_test, unaugmented = args.unaug_dataset,
                                           xgb_clf=args.xgb_clf, KNN_clf=args.KNN_clf, rf_clf=args.rf_clf)
    else:
        y_rl = pd.DataFrame(pd.read_csv("/home/silver/PycharmProjects/AAEDRL/clfs/labels.csv"))
        y_rl = y_rl[y_rl["attack_cat"] != 2] # 2 is a majority class so we drop it
        y = pd.concat([y_rl, main_u.y], axis=0) # Join all labels
        y = y.squeeze() # If extra dim from converting a dataframe to a series
        X_train, X_test, y_train, y_test = main_u.vertical_split(X, y[:173252]) # Split dataset (the synthetic dataset was generated using interpolation, sometimes there's mismatch in size)
    
        benchmark_classification.clf_class(X_train, X_test, y_train, y_test, unaugmented = args.unaug_dataset, xgb_clf=args.xgb_clf, KNN_clf=args.KNN_clf,
                                           rf_clf=args.rf_clf)
